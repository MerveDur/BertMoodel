{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BertCoraDataset.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Gerekli kütüphaneler eklendi."
      ],
      "metadata": {
        "id": "DyjH_8M5t738"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrYO6HDoRNNP",
        "outputId": "08ffea4b-8c0f-4a27-946f-36fbf5fe88cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "import numpy as np\n",
        "import time\n",
        "import datetime\n",
        "import random\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "!pip install transformers\n",
        "import transformers\n",
        "from transformers import BertTokenizer\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.15.0-py3-none-any.whl (3.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.4 MB 12.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 5.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 48.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.10.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 48.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 45.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.47 tokenizers-0.10.3 transformers-4.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gpu kontrolü"
      ],
      "metadata": {
        "id": "sK2zyG-CuZuo"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCCSYp9sSlSD",
        "outputId": "5bb247c1-a26a-4dbb-f08b-90e0785ce50a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# check GPU\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name == '/device:GPU:0':\n",
        "    device = torch.device(\"cuda\")\n",
        "    print('GPU:', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU: Tesla K80\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset path kaydediliyor,google drive ile bağlantı kuruluyor"
      ],
      "metadata": {
        "id": "gDZlIxTVvFUS"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tc-DVN1S448",
        "outputId": "82ca060d-c543-445d-e66f-0ce01690f585",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# set environment as googledrive to folder \"resource\"\n",
        "data_path =  \"/resource/\"\n",
        "\n",
        "try:\n",
        "    drive.mount('/content/drive')\n",
        "    data_path = \"/content/drive/My Drive/resource/\"\n",
        "\n",
        "except:\n",
        "    print(\"You are not working in Colab at the moment :(\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset okunuyor"
      ],
      "metadata": {
        "id": "NWaW8y9uvL0I"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Nt6KR1ZTMEh"
      },
      "source": [
        "df = pd.read_csv(data_path + 'coraDataset.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset bilgileri yazdırılıyor"
      ],
      "metadata": {
        "id": "COSG4rK8vbEA"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaWQQe3yTYab",
        "outputId": "a78d1d20-8429-407e-fdf8-741e738fa337",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2708 entries, 0 to 2707\n",
            "Data columns (total 2 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   category  2708 non-null   object\n",
            " 1   text      2708 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 42.4+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Datasetten 10 örnek gösteriliyor"
      ],
      "metadata": {
        "id": "HatEHhwhvlbI"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOTi-A1UTc24",
        "outputId": "cd0a2223-5d8b-405c-cc66-f710ff7223d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "source": [
        "df.sample(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-d06a5e37-f553-43de-a30f-312a7be05f66\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1579</th>\n",
              "      <td>Neural_Networks</td>\n",
              "      <td>support vector machin approach decis tree key ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2539</th>\n",
              "      <td>Theory</td>\n",
              "      <td>mdl mml similar differ introduct minimum encod...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1369</th>\n",
              "      <td>Theory</td>\n",
              "      <td>bayesian method adapt model forward probabl us...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2198</th>\n",
              "      <td>Neural_Networks</td>\n",
              "      <td>temper backpropag network weight creat equal a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>617</th>\n",
              "      <td>Probabilistic_Methods</td>\n",
              "      <td>improv model spatial correl binari respons pap...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>137</th>\n",
              "      <td>Neural_Networks</td>\n",
              "      <td>stabil chao inerti two neuron system statist m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2681</th>\n",
              "      <td>Theory</td>\n",
              "      <td>develop probabilist model neural network ensem...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2514</th>\n",
              "      <td>Neural_Networks</td>\n",
              "      <td>analyt framework local feedforward network int...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>Genetic_Algorithms</td>\n",
              "      <td>evolutionari cost learn trait acquir member ev...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>298</th>\n",
              "      <td>Genetic_Algorithms</td>\n",
              "      <td>reformul design optim strategi automat design ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d06a5e37-f553-43de-a30f-312a7be05f66')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d06a5e37-f553-43de-a30f-312a7be05f66 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d06a5e37-f553-43de-a30f-312a7be05f66');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                   category                                               text\n",
              "1579        Neural_Networks  support vector machin approach decis tree key ...\n",
              "2539                 Theory  mdl mml similar differ introduct minimum encod...\n",
              "1369                 Theory  bayesian method adapt model forward probabl us...\n",
              "2198        Neural_Networks  temper backpropag network weight creat equal a...\n",
              "617   Probabilistic_Methods  improv model spatial correl binari respons pap...\n",
              "137         Neural_Networks  stabil chao inerti two neuron system statist m...\n",
              "2681                 Theory  develop probabilist model neural network ensem...\n",
              "2514        Neural_Networks  analyt framework local feedforward network int...\n",
              "26       Genetic_Algorithms  evolutionari cost learn trait acquir member ev...\n",
              "298      Genetic_Algorithms  reformul design optim strategi automat design ..."
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Datasetteki etiket sayıları gösteriliyor"
      ],
      "metadata": {
        "id": "kkHIH36Svtvd"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEcaS2orThoy",
        "outputId": "16ef2f18-69b8-4442-ec91-049f1973c259",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df.groupby('category').size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "category\n",
              "Case_Based                298\n",
              "Genetic_Algorithms        418\n",
              "Neural_Networks           818\n",
              "Probabilistic_Methods     426\n",
              "Reinforcement_Learning    217\n",
              "Rule_Learning             180\n",
              "Theory                    351\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Labelleri encode ediyoruz"
      ],
      "metadata": {
        "id": "x8DKy_A4X8uR"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOo9dA56_7Oy"
      },
      "source": [
        "df['encoded_categories'] = LabelEncoder().fit_transform(df['category'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenizer indirildi\n",
        "Bert modeli indirildi"
      ],
      "metadata": {
        "id": "qxzy7d33YF_k"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtmbRhroAtCd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c6c7cc8-4b9f-4770-a93d-7729d0e96a3f"
      },
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n",
        "  \n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "model = AutoModel.from_pretrained(\"bert-base-uncased\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sentences a text leri atıyoruz"
      ],
      "metadata": {
        "id": "qxnmD_LjYYaK"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DzbC8f7AxAC"
      },
      "source": [
        "sentences = df.text.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Max kelime sayısını 200 yapıyoruz GPU hatası almamak için"
      ],
      "metadata": {
        "id": "yJX24w6QYpKd"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPgQuTUGA1ct"
      },
      "source": [
        "max_len = 200"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "%80 ve %20 oranıyla  training ve test olarak veriyi ikiye bölcdüm"
      ],
      "metadata": {
        "id": "oZu47gjWYwbG"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AsHlvfa1A9J_"
      },
      "source": [
        "training = df.groupby('category').apply(lambda x : x.sample(frac = 0.8))\n",
        "test = pd.concat([df,training]).drop_duplicates(keep=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYiFqjplA_e4",
        "outputId": "6ad7cd8a-46ff-457d-e877-1933db07f42e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"Training: \", len(training))\n",
        "print(\"Test: \", len(test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training:  2166\n",
            "Test:  538\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6PuTo9fHBBFd"
      },
      "source": [
        "training_texts = training.text.values\n",
        "training_labels = training.encoded_categories.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cümleler tokenizer ile bölünüyor\n",
        "Max uzunluğa göre ayarlamalar yapılıyor\n",
        "Attention mask yapılıyor\n",
        "Tensor objesi oluşturuluyor\n",
        "Kelimeler id lerle ifade ediliyor"
      ],
      "metadata": {
        "id": "ndVqLZQwZtAl"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AavMUW7oBESR",
        "outputId": "b5d09112-75a3-43e7-aabc-b2cfcde92979",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "for text in training_texts:\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        text,                     \n",
        "                        add_special_tokens = True,\n",
        "                        max_length = max_len,      \n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True, \n",
        "                        return_tensors = 'pt',\n",
        "                   )\n",
        "    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(training_labels)\n",
        "\n",
        "print('Original: ', training_texts[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2232: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:  correct length bias convers case score infer convers case base reason ccbr approach embed cbr content navig line product suscept bia case score algorithm particular shorter case tend given higher score assum factor held constant report summar investig mediat bia introduc approach elimin bia evalu affect retriev perform six case librari also suggest explan result note limit studi rel frequenc select solut solv given problem retriev effici defin invers function number question answer solut retriev bias case score develop ccbr tool name nacoda navi convers decis aid environ breslow aha combin bias shorter longer case sometim effect use one isol use leav one aha breslow strategi evalu case retriev perform strategi similar well known leav one cross valid except case ever remov case librari might uniqu respect solut date approach test simultan increas retriev precis retriev effici case librari revis describ aha breslow initi analysi result show clear statist trend explain expect new case score algorithm deliv higher precis\n",
            "Token IDs: tensor([  101,  6149,  3091, 13827,  9530, 14028,  2553,  3556,  1999,  7512,\n",
            "         9530, 14028,  2553,  2918,  3114, 10507, 19892,  3921,  7861,  8270,\n",
            "        17324,  2099,  4180,  6583,  5737,  2290,  2240,  4031, 10514, 11020,\n",
            "        23606, 12170,  2050,  2553,  3556,  9896,  3327,  7820,  2553,  7166,\n",
            "         2445,  3020,  3556,  4632,  2819,  5387,  2218,  5377,  3189,  7680,\n",
            "         7849, 15697,  8004,  2865,  2102, 12170,  2050, 17174,  8566,  2278,\n",
            "         3921, 12005, 10020, 12170,  2050,  9345,  7630,  7461,  2128, 18886,\n",
            "         6777,  4685,  2416,  2553,  5622, 10024,  3089,  2036,  6592,  4654,\n",
            "        24759,  2319,  2765,  3602,  5787, 16054,  2072,  2128,  2140, 10424,\n",
            "         2063,  4226, 12273,  7276, 14017,  4904, 14017,  2615,  2445,  3291,\n",
            "         2128, 18886,  6777,  1041, 26989,  6895, 13366,  2378,  1999, 14028,\n",
            "         3853,  2193,  3160,  3437, 14017,  4904,  2128, 18886,  6777, 13827,\n",
            "         2553,  3556,  4503, 10507, 19892,  6994,  2171,  6583,  3597,  2850,\n",
            "         6583,  5737,  9530, 14028, 11703,  2483,  4681,  4372, 21663,  2239,\n",
            "         7987,  2229,  8261,  6289,  2050, 22863,  2378, 13827,  7820,  2936,\n",
            "         2553,  2070,  3775,  2213,  3466,  2224,  2028, 11163,  2140,  2224,\n",
            "        12203,  2615,  2028,  6289,  2050,  7987,  2229,  8261,  2358, 11657,\n",
            "         5856,  9345,  7630,  2553,  2128, 18886,  6777,  4685,  2358, 11657,\n",
            "         5856,  2714,  2092,  2124, 12203,  2615,  2028,  2892,  9398,  3272,\n",
            "         2553,  2412,  2128,  5302,  2615,  2553,  5622, 10024,  3089,   102])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tensor objesi dataloadera verilip model e uygun hale getiriliyorBatch size aynı anda kaç verinin işleneceğini belirler"
      ],
      "metadata": {
        "id": "5qatE1dramy9"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4YUhZxyCwVF"
      },
      "source": [
        "train_dataset = TensorDataset(input_ids, attention_masks, labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTUsi4QGBxQr"
      },
      "source": [
        "batch_size = 32\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  \n",
        "            sampler = RandomSampler(train_dataset), \n",
        "            batch_size = batch_size \n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dxa9wOcVCzq8"
      },
      "source": [
        "number_of_categories = len(df['encoded_categories'].unique())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fine tuning işlemi yapılıyor"
      ],
      "metadata": {
        "id": "8aiYFyIpbT6M"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfNDxpE3C2bP",
        "outputId": "c75955cd-d4d2-4c12-e9d8-ea7697feb612",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#model = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\",\n",
        "    num_labels = number_of_categories, \n",
        "    output_attentions = False,\n",
        "    output_hidden_states = False,\n",
        ")\n",
        "\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=7, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train epoch sayısı verilip eğitim yapılıyor"
      ],
      "metadata": {
        "id": "Q8ag5Ikobunp"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPL4qSPkC8hx"
      },
      "source": [
        "epochs = 15\n",
        "\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 5e-5,\n",
        "                  eps = 1e-8 \n",
        "                )\n",
        "\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0,\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqFHIKBhE9wv"
      },
      "source": [
        "def format_time(elapsed):\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Or7cXZA9DPs4",
        "outputId": "8e3f28f8-4c68-4b0f-97c2-8801e390df02",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "seed_val = 1903\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "training_stats = []\n",
        "total_t0 = time.time()\n",
        "\n",
        "for epoch_i in range(0, epochs):\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    t0 = time.time()\n",
        "    total_train_loss = 0\n",
        "    model.train()\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        if step % 10 == 0 and not step == 0:\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            print('Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        model.zero_grad()        \n",
        "        output = model(b_input_ids, \n",
        "                             token_type_ids=None, \n",
        "                             attention_mask=b_input_mask, \n",
        "                             labels=b_labels)\n",
        "        loss = output['loss']\n",
        "        logits = output['logits']\n",
        "        total_train_loss += loss.item()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"Training epoch took: {:}\".format(training_time))\n",
        "\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Training Time': training_time,\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"Training completed in {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======== Epoch 1 / 15 ========\n",
            "Batch    10  of     68.    Elapsed: 0:00:22.\n",
            "Batch    20  of     68.    Elapsed: 0:00:43.\n",
            "Batch    30  of     68.    Elapsed: 0:01:05.\n",
            "Batch    40  of     68.    Elapsed: 0:01:26.\n",
            "Batch    50  of     68.    Elapsed: 0:01:48.\n",
            "Batch    60  of     68.    Elapsed: 0:02:09.\n",
            "Average training loss: 1.05\n",
            "Training epoch took: 0:02:26\n",
            "======== Epoch 2 / 15 ========\n",
            "Batch    10  of     68.    Elapsed: 0:00:21.\n",
            "Batch    20  of     68.    Elapsed: 0:00:43.\n",
            "Batch    30  of     68.    Elapsed: 0:01:04.\n",
            "Batch    40  of     68.    Elapsed: 0:01:26.\n",
            "Batch    50  of     68.    Elapsed: 0:01:47.\n",
            "Batch    60  of     68.    Elapsed: 0:02:09.\n",
            "Average training loss: 0.77\n",
            "Training epoch took: 0:02:25\n",
            "======== Epoch 3 / 15 ========\n",
            "Batch    10  of     68.    Elapsed: 0:00:21.\n",
            "Batch    20  of     68.    Elapsed: 0:00:43.\n",
            "Batch    30  of     68.    Elapsed: 0:01:04.\n",
            "Batch    40  of     68.    Elapsed: 0:01:26.\n",
            "Batch    50  of     68.    Elapsed: 0:01:47.\n",
            "Batch    60  of     68.    Elapsed: 0:02:09.\n",
            "Average training loss: 0.49\n",
            "Training epoch took: 0:02:25\n",
            "======== Epoch 4 / 15 ========\n",
            "Batch    10  of     68.    Elapsed: 0:00:21.\n",
            "Batch    20  of     68.    Elapsed: 0:00:43.\n",
            "Batch    30  of     68.    Elapsed: 0:01:04.\n",
            "Batch    40  of     68.    Elapsed: 0:01:26.\n",
            "Batch    50  of     68.    Elapsed: 0:01:47.\n",
            "Batch    60  of     68.    Elapsed: 0:02:09.\n",
            "Average training loss: 0.36\n",
            "Training epoch took: 0:02:25\n",
            "======== Epoch 5 / 15 ========\n",
            "Batch    10  of     68.    Elapsed: 0:00:21.\n",
            "Batch    20  of     68.    Elapsed: 0:00:43.\n",
            "Batch    30  of     68.    Elapsed: 0:01:04.\n",
            "Batch    40  of     68.    Elapsed: 0:01:26.\n",
            "Batch    50  of     68.    Elapsed: 0:01:47.\n",
            "Batch    60  of     68.    Elapsed: 0:02:08.\n",
            "Average training loss: 0.26\n",
            "Training epoch took: 0:02:25\n",
            "======== Epoch 6 / 15 ========\n",
            "Batch    10  of     68.    Elapsed: 0:00:21.\n",
            "Batch    20  of     68.    Elapsed: 0:00:43.\n",
            "Batch    30  of     68.    Elapsed: 0:01:04.\n",
            "Batch    40  of     68.    Elapsed: 0:01:26.\n",
            "Batch    50  of     68.    Elapsed: 0:01:47.\n",
            "Batch    60  of     68.    Elapsed: 0:02:09.\n",
            "Average training loss: 0.18\n",
            "Training epoch took: 0:02:25\n",
            "======== Epoch 7 / 15 ========\n",
            "Batch    10  of     68.    Elapsed: 0:00:21.\n",
            "Batch    20  of     68.    Elapsed: 0:00:43.\n",
            "Batch    30  of     68.    Elapsed: 0:01:04.\n",
            "Batch    40  of     68.    Elapsed: 0:01:26.\n",
            "Batch    50  of     68.    Elapsed: 0:01:47.\n",
            "Batch    60  of     68.    Elapsed: 0:02:09.\n",
            "Average training loss: 0.12\n",
            "Training epoch took: 0:02:25\n",
            "======== Epoch 8 / 15 ========\n",
            "Batch    10  of     68.    Elapsed: 0:00:21.\n",
            "Batch    20  of     68.    Elapsed: 0:00:43.\n",
            "Batch    30  of     68.    Elapsed: 0:01:04.\n",
            "Batch    40  of     68.    Elapsed: 0:01:26.\n",
            "Batch    50  of     68.    Elapsed: 0:01:47.\n",
            "Batch    60  of     68.    Elapsed: 0:02:09.\n",
            "Average training loss: 0.09\n",
            "Training epoch took: 0:02:25\n",
            "======== Epoch 9 / 15 ========\n",
            "Batch    10  of     68.    Elapsed: 0:00:21.\n",
            "Batch    20  of     68.    Elapsed: 0:00:43.\n",
            "Batch    30  of     68.    Elapsed: 0:01:04.\n",
            "Batch    40  of     68.    Elapsed: 0:01:26.\n",
            "Batch    50  of     68.    Elapsed: 0:01:47.\n",
            "Batch    60  of     68.    Elapsed: 0:02:09.\n",
            "Average training loss: 0.06\n",
            "Training epoch took: 0:02:25\n",
            "======== Epoch 10 / 15 ========\n",
            "Batch    10  of     68.    Elapsed: 0:00:21.\n",
            "Batch    20  of     68.    Elapsed: 0:00:43.\n",
            "Batch    30  of     68.    Elapsed: 0:01:04.\n",
            "Batch    40  of     68.    Elapsed: 0:01:26.\n",
            "Batch    50  of     68.    Elapsed: 0:01:47.\n",
            "Batch    60  of     68.    Elapsed: 0:02:09.\n",
            "Average training loss: 0.03\n",
            "Training epoch took: 0:02:25\n",
            "======== Epoch 11 / 15 ========\n",
            "Batch    10  of     68.    Elapsed: 0:00:21.\n",
            "Batch    20  of     68.    Elapsed: 0:00:43.\n",
            "Batch    30  of     68.    Elapsed: 0:01:04.\n",
            "Batch    40  of     68.    Elapsed: 0:01:26.\n",
            "Batch    50  of     68.    Elapsed: 0:01:47.\n",
            "Batch    60  of     68.    Elapsed: 0:02:09.\n",
            "Average training loss: 0.02\n",
            "Training epoch took: 0:02:25\n",
            "======== Epoch 12 / 15 ========\n",
            "Batch    10  of     68.    Elapsed: 0:00:21.\n",
            "Batch    20  of     68.    Elapsed: 0:00:43.\n",
            "Batch    30  of     68.    Elapsed: 0:01:04.\n",
            "Batch    40  of     68.    Elapsed: 0:01:26.\n",
            "Batch    50  of     68.    Elapsed: 0:01:47.\n",
            "Batch    60  of     68.    Elapsed: 0:02:09.\n",
            "Average training loss: 0.01\n",
            "Training epoch took: 0:02:25\n",
            "======== Epoch 13 / 15 ========\n",
            "Batch    10  of     68.    Elapsed: 0:00:21.\n",
            "Batch    20  of     68.    Elapsed: 0:00:43.\n",
            "Batch    30  of     68.    Elapsed: 0:01:04.\n",
            "Batch    40  of     68.    Elapsed: 0:01:26.\n",
            "Batch    50  of     68.    Elapsed: 0:01:47.\n",
            "Batch    60  of     68.    Elapsed: 0:02:09.\n",
            "Average training loss: 0.01\n",
            "Training epoch took: 0:02:25\n",
            "======== Epoch 14 / 15 ========\n",
            "Batch    10  of     68.    Elapsed: 0:00:21.\n",
            "Batch    20  of     68.    Elapsed: 0:00:43.\n",
            "Batch    30  of     68.    Elapsed: 0:01:04.\n",
            "Batch    40  of     68.    Elapsed: 0:01:26.\n",
            "Batch    50  of     68.    Elapsed: 0:01:47.\n",
            "Batch    60  of     68.    Elapsed: 0:02:09.\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:02:25\n",
            "======== Epoch 15 / 15 ========\n",
            "Batch    10  of     68.    Elapsed: 0:00:21.\n",
            "Batch    20  of     68.    Elapsed: 0:00:43.\n",
            "Batch    30  of     68.    Elapsed: 0:01:04.\n",
            "Batch    40  of     68.    Elapsed: 0:01:26.\n",
            "Batch    50  of     68.    Elapsed: 0:01:47.\n",
            "Batch    60  of     68.    Elapsed: 0:02:09.\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:02:25\n",
            "Training completed in 0:36:19 (h:mm:ss)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sonuçlar İnceleniyor"
      ],
      "metadata": {
        "id": "4mCokC4KcKsV"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEX93h5OE-pG",
        "outputId": "ff49801b-69e4-4157-d115-0174661c75b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "plt.plot(df_stats['Training Loss'], label=\"Training\")\n",
        "plt.title(\"Training Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.xticks([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test içinde traning işlemi yapılıyor"
      ],
      "metadata": {
        "id": "cvrmV6jUcX1P"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xa3aIdMyJwm-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "916ed6ff-65c3-45dc-e4f4-3b68862d12a8"
      },
      "source": [
        "test_texts = test.text.values\n",
        "test_labels = test.encoded_categories.values\n",
        "\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "for text in test_texts:\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        text,                     \n",
        "                        add_special_tokens = True, \n",
        "                        max_length = max_len,          \n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,  \n",
        "                        return_tensors = 'pt',   \n",
        "                   )\n",
        "    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(test_labels)\n",
        "\n",
        "batch_size = 32  \n",
        "\n",
        "prediction_data = TensorDataset(input_ids, attention_masks, labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2232: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "OkxFaQq0cgw4"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RNfzOIZKH82",
        "outputId": "884b3e2d-a35b-4275-a952-81097b396d7d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print('Prediction started on test data')\n",
        "model.eval()\n",
        "predictions , true_labels = [], []\n",
        "\n",
        "for batch in prediction_dataloader:\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "  with torch.no_grad():\n",
        "      outputs = model(b_input_ids, token_type_ids=None, \n",
        "                      attention_mask=b_input_mask)\n",
        "\n",
        "  logits = outputs[0]\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "print('Prediction completed')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction started on test data\n",
            "Prediction completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNJdxER7KeBH"
      },
      "source": [
        "prediction_set = []\n",
        "\n",
        "for i in range(len(true_labels)):\n",
        "  pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
        "  prediction_set.append(pred_labels_i)\n",
        "\n",
        "prediction_scores = [item for sublist in prediction_set for item in sublist]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tk4NmFh0KjLu"
      },
      "source": [
        "f_score = f1_score(test_labels, prediction_scores, average='macro')\n",
        "precision = precision_score(test_labels, prediction_scores, average='macro')\n",
        "recall = recall_score(test_labels, prediction_scores, average='macro')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQaJueaUKlQf",
        "outputId": "2ec49751-ebbb-45e8-e380-0b7808bdc9a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"F-Score: \", f_score)\n",
        "print(\"Recall: \", recall)\n",
        "print(\"Precision: \", precision)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F-Score:  0.8060891766192311\n",
            "Recall:  0.8223676851425334\n",
            "Precision:  0.7978703975879714\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTaAxtnyKnzf"
      },
      "source": [
        "report = pd.DataFrame(classification_report(test_labels, prediction_scores, output_dict=True))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CyJ5RCD-Kqur"
      },
      "source": [
        "report = report.rename(columns={'0':'Case_Based',\n",
        "                          '1':'Genetic_Algorithms',\n",
        "                          '2':'Neural_Networks',\n",
        "                          '3':'Probabilistic_Methods',\n",
        "                          '4':'Reinforcement_Learning',\n",
        "                          '5':'Rule_Learning',\n",
        "                          '6':'Theory'})\n",
        "\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zjp7m2NRMoRp",
        "outputId": "2901f8b4-1ab2-4296-e01a-2525305b2527",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        }
      },
      "source": [
        "report"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-0ea3e04f-7072-4195-bd76-f84d494982a7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Case_Based</th>\n",
              "      <th>Genetic_Algorithms</th>\n",
              "      <th>Neural_Networks</th>\n",
              "      <th>Probabilistic_Methods</th>\n",
              "      <th>Reinforcement_Learning</th>\n",
              "      <th>Rule_Learning</th>\n",
              "      <th>Theory</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>macro avg</th>\n",
              "      <th>weighted avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>precision</th>\n",
              "      <td>0.851852</td>\n",
              "      <td>0.897436</td>\n",
              "      <td>0.896104</td>\n",
              "      <td>0.822785</td>\n",
              "      <td>0.706897</td>\n",
              "      <td>0.707317</td>\n",
              "      <td>0.702703</td>\n",
              "      <td>0.819703</td>\n",
              "      <td>0.797870</td>\n",
              "      <td>0.827220</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recall</th>\n",
              "      <td>0.766667</td>\n",
              "      <td>0.853659</td>\n",
              "      <td>0.846626</td>\n",
              "      <td>0.764706</td>\n",
              "      <td>0.953488</td>\n",
              "      <td>0.828571</td>\n",
              "      <td>0.742857</td>\n",
              "      <td>0.819703</td>\n",
              "      <td>0.822368</td>\n",
              "      <td>0.819703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f1-score</th>\n",
              "      <td>0.807018</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>0.870662</td>\n",
              "      <td>0.792683</td>\n",
              "      <td>0.811881</td>\n",
              "      <td>0.763158</td>\n",
              "      <td>0.722222</td>\n",
              "      <td>0.819703</td>\n",
              "      <td>0.806089</td>\n",
              "      <td>0.820900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>support</th>\n",
              "      <td>60.000000</td>\n",
              "      <td>82.000000</td>\n",
              "      <td>163.000000</td>\n",
              "      <td>85.000000</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>70.000000</td>\n",
              "      <td>0.819703</td>\n",
              "      <td>538.000000</td>\n",
              "      <td>538.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0ea3e04f-7072-4195-bd76-f84d494982a7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0ea3e04f-7072-4195-bd76-f84d494982a7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0ea3e04f-7072-4195-bd76-f84d494982a7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "           Case_Based  Genetic_Algorithms  ...   macro avg  weighted avg\n",
              "precision    0.851852            0.897436  ...    0.797870      0.827220\n",
              "recall       0.766667            0.853659  ...    0.822368      0.819703\n",
              "f1-score     0.807018            0.875000  ...    0.806089      0.820900\n",
              "support     60.000000           82.000000  ...  538.000000    538.000000\n",
              "\n",
              "[4 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    }
  ]
}